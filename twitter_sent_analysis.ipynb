{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model,Input\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "RbtKLh5VsUNr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'https://raw.githubusercontent.com/malinphy/datasets/main/tweet_sentiment_extraction/twitter_sentiment_analysis/twitter_training.csv'\n",
        "test_path = 'https://raw.githubusercontent.com/malinphy/datasets/main/tweet_sentiment_extraction/twitter_sentiment_analysis/twitter_validation.csv'"
      ],
      "metadata": {
        "id": "xLHJtxOysULB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_csv(train_path,header = None).dropna().reset_index(drop= True)\n",
        "test_df = pd.read_csv(test_path,header = None).reset_index(drop= True)\n",
        "train_df = train_df.rename(columns={0: 'tweet_id', 1: 'entity',2:'sentiment',3:'content'})\n",
        "test_df = test_df.rename(columns={0: 'tweet_id', 1: 'entity',2:'sentiment',3:'content'})"
      ],
      "metadata": {
        "id": "01kGm-sAsUIi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 45000\n",
        "embed_dim = 32\n",
        "input_len = 170"
      ],
      "metadata": {
        "id": "n7GmCEL5tFhX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        " max_tokens=vocab_size,\n",
        " output_mode='int',\n",
        " output_sequence_length=170\n",
        " )\n",
        "\n",
        "vectorize_layer.adapt(train_df['content'])\n",
        "train_tokens = vectorize_layer(train_df['content'])\n",
        "test_tokens = vectorize_layer(test_df['content'])"
      ],
      "metadata": {
        "id": "5K7J93aYufoI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = tf.shape(train_tokens)[1]\n",
        "corpus_size = len(vectorize_layer.get_vocabulary())"
      ],
      "metadata": {
        "id": "Tu0HA996F3ek"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LE = LabelEncoder()\n",
        "train_encoded_labels = LE.fit_transform(train_df['sentiment'])\n",
        "test_encoded_labels = LE.transform(test_df['sentiment'])"
      ],
      "metadata": {
        "id": "fqdqArJjEkog"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(input_len,), name = 'input_layer')\n",
        "emb_layer = Embedding(vocab_size, embed_dim, name = 'embedding_layer')(input_layer)\n",
        "flat_layer = Flatten(name = 'Flatten_layer')(emb_layer)\n",
        "d1_layer = Dense(128,activation = 'relu',name = 'd1_layer')(flat_layer)\n",
        "d2_layer = Dense(64,activation = 'relu',name = 'd2_layer')(d1_layer)\n",
        "d3_layer = Dense(32,activation = 'relu',name = 'd3_layer')(d2_layer)\n",
        "final_layer = Dense(4,activation = 'softmax',name = 'final_layer')(d3_layer)\n",
        "model = Model(inputs = input_layer, outputs = final_layer)\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_tokens,\n",
        "    train_encoded_labels,\n",
        "    epochs = 8\n",
        ")"
      ],
      "metadata": {
        "id": "0I-kmBDDEw2Y",
        "outputId": "81af4679-11ac-4334-d16b-29ae51163b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "2313/2313 [==============================] - 71s 30ms/step - loss: 0.8103 - accuracy: 0.6587\n",
            "Epoch 2/8\n",
            "2313/2313 [==============================] - 64s 28ms/step - loss: 0.2269 - accuracy: 0.9179\n",
            "Epoch 3/8\n",
            "2313/2313 [==============================] - 66s 28ms/step - loss: 0.1237 - accuracy: 0.9537\n",
            "Epoch 4/8\n",
            "2313/2313 [==============================] - 63s 27ms/step - loss: 0.0965 - accuracy: 0.9621\n",
            "Epoch 5/8\n",
            "2313/2313 [==============================] - 61s 27ms/step - loss: 0.0859 - accuracy: 0.9659\n",
            "Epoch 6/8\n",
            "2313/2313 [==============================] - 61s 26ms/step - loss: 0.0772 - accuracy: 0.9678\n",
            "Epoch 7/8\n",
            "2313/2313 [==============================] - 63s 27ms/step - loss: 0.0715 - accuracy: 0.9703\n",
            "Epoch 8/8\n",
            "2313/2313 [==============================] - 63s 27ms/step - loss: 0.0681 - accuracy: 0.9709\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6fde83a50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = tf.math.top_k(model.predict( test_tokens), k=1 )[1]"
      ],
      "metadata": {
        "id": "_Er6iD84FZEF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_encoded_labels, preds)"
      ],
      "metadata": {
        "id": "WMpX4yR-IqA3",
        "outputId": "e9356902-a458-4a19-c347-041bd92e04a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[170,   1,   0,   1],\n",
              "       [  0, 265,   0,   1],\n",
              "       [  1,   4, 275,   5],\n",
              "       [  1,   1,   3, 272]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('f1 score',f1_score(test_encoded_labels, preds, average= 'macro'))\n",
        "print(classification_report(test_encoded_labels, preds, labels = [0,1,2,3]))"
      ],
      "metadata": {
        "id": "DcwCRL_-Iz5n",
        "outputId": "642c8bcf-e56a-43d6-9791-d38f2100d5e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score 0.9826658478285479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       172\n",
            "           1       0.98      1.00      0.99       266\n",
            "           2       0.99      0.96      0.98       285\n",
            "           3       0.97      0.98      0.98       277\n",
            "\n",
            "    accuracy                           0.98      1000\n",
            "   macro avg       0.98      0.98      0.98      1000\n",
            "weighted avg       0.98      0.98      0.98      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF_classifier= RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "RF_classifier.fit( train_tokens,train_encoded_labels)"
      ],
      "metadata": {
        "id": "jMvTLFi8ZmGu",
        "outputId": "c5b7ef18-4e7a-4ae8-cbb7-0f897cce1e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=1000, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF_pred = RF_classifier.predict(test_tokens)\n",
        "print(classification_report(test_encoded_labels, RF_pred, labels = [0,1,2,3]))"
      ],
      "metadata": {
        "id": "1FiDZ5JKgioQ",
        "outputId": "70dc7c05-6da4-4745-f093-0d41b2acda2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92       172\n",
            "           1       0.85      0.97      0.90       266\n",
            "           2       0.91      0.87      0.89       285\n",
            "           3       0.94      0.90      0.92       277\n",
            "\n",
            "    accuracy                           0.91      1000\n",
            "   macro avg       0.91      0.90      0.91      1000\n",
            "weighted avg       0.91      0.91      0.91      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_classifier = LinearSVC()\n",
        "SVC_classifier.fit( train_tokens,train_encoded_labels)"
      ],
      "metadata": {
        "id": "8vZlu7VShqwl",
        "outputId": "bf5fa1e0-e9e7-4ca1-ed85-8a935fee9cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_pred = SVC_classifier.predict(test_tokens)\n",
        "print(classification_report(test_encoded_labels, SVC_pred, labels = [0,1,2,3]))"
      ],
      "metadata": {
        "id": "8_Fj3brhhs5s",
        "outputId": "d9f72815-b752-4dca-cb9a-701ba14d2219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.37      0.27       172\n",
            "           1       0.25      0.09      0.13       266\n",
            "           2       0.16      0.04      0.06       285\n",
            "           3       0.30      0.60      0.40       277\n",
            "\n",
            "    accuracy                           0.26      1000\n",
            "   macro avg       0.23      0.27      0.21      1000\n",
            "weighted avg       0.23      0.26      0.21      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9SEstGshswb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPzSpj_8hss5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIhkuHE7hsp-"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}